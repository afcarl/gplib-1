{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/Users/IzmailovPavel/Documents/Education/GPproject/gplib/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "Testing gplib.optim \n",
    "## Deterministic methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(12, 12)\n",
    "A = A.T.dot(A) + np.eye(12)*0.5\n",
    "b = np.random.rand(12).reshape((12, 1))\n",
    "def f(x):\n",
    "    \"\"\"for minimization\"\"\"\n",
    "    x = x.reshape((x.size, 1))\n",
    "    fun = x.T.dot(A.dot(x)) / 2 + b.T.dot(x)\n",
    "    grad = A.dot(x) + b\n",
    "    return fun[0, 0], grad.reshape(-1)\n",
    "\n",
    "def f2(x):\n",
    "    \"\"\"for maximization, with hessian\"\"\"\n",
    "    x = x.reshape((x.size, 1))\n",
    "    fun = -x.T.dot(A.dot(x)) / 2 - b.T.dot(x)\n",
    "    grad = -A.dot(x) - b\n",
    "    hess = -A\n",
    "    return fun[0, 0], grad.reshape(-1), hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_0 = np.random.rand(12).reshape(12,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gplib.optim.utility import check_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Difference between calculated and approximated gradients\n",
      "7.79829121056e-06\n"
     ]
    }
   ],
   "source": [
    "check_gradient(f, x_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scipy.L-BFGS-B wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gplib.optim.methods import LBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = LBFGS(maxiter=20, disp=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :\n",
      "\tx [ 0.0672269   0.25084111  0.85310949  0.94455894  0.31832569]\n",
      "Iteration 5 :\n",
      "\tx [ 0.00888674 -0.07168481  0.22909253 -0.05835525 -0.30975145]\n",
      "Iteration 10 :\n",
      "\tx [ 0.08214552 -0.0711999   0.29856264 -0.15992151 -0.42189632]\n",
      "Iteration 15 :\n",
      "\tx [ 0.08337992 -0.0720693   0.29747764 -0.16006448 -0.42249568]\n"
     ]
    }
   ],
   "source": [
    "x, stat = optimizer.minimize(f, x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002584695816040039"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2755426265523222"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat['fun']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGD with armiho step-size rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gplib.optim.methods import FGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = FGD(maxiter=100, disp=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 :\n",
      "\tGradient projection norm 73.2433491075\n",
      "\tFunction value 71.8867684491\n",
      "Iteration  10 :\n",
      "\tGradient projection norm 1.12076127815\n",
      "\tFunction value -0.109996487424\n",
      "Iteration  20 :\n",
      "\tGradient projection norm 0.834438786714\n",
      "\tFunction value -0.220581263237\n",
      "Iteration  30 :\n",
      "\tGradient projection norm 0.172473479271\n",
      "\tFunction value -0.257858065265\n",
      "Iteration  40 :\n",
      "\tGradient projection norm 0.112893224102\n",
      "\tFunction value -0.268718037258\n",
      "Iteration  50 :\n",
      "\tGradient projection norm 0.152922694631\n",
      "\tFunction value -0.272786881311\n",
      "Iteration  60 :\n",
      "\tGradient projection norm 0.0384195754519\n",
      "\tFunction value -0.274485851026\n",
      "Iteration  70 :\n",
      "\tGradient projection norm 0.0255323766013\n",
      "\tFunction value -0.27510360217\n",
      "Iteration  80 :\n",
      "\tGradient projection norm 0.0173577402903\n",
      "\tFunction value -0.275357653722\n",
      "Iteration  90 :\n",
      "\tGradient projection norm 0.0224832157868\n",
      "\tFunction value -0.27546458113\n"
     ]
    }
   ],
   "source": [
    "x, stat = optimizer.minimize(f, x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015423059463500977"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.27550630389258479"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat['fun']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected Newton\n",
    "#### Without Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gplib.optim.methods import ProjNewton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = ProjNewton(maxiter=20, disp=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 :\n",
      "\tGradient projection norm 253.722403941\n",
      "\tFunction value 71.8867684491\n",
      "Iteration  5 :\n",
      "\tGradient projection norm 0.47023128676\n",
      "\tFunction value -0.273979961261\n",
      "Iteration  10 :\n",
      "\tGradient projection norm 0.0249156073566\n",
      "\tFunction value -0.275541680521\n",
      "Iteration  15 :\n",
      "\tGradient projection norm 0.000259808616059\n",
      "\tFunction value -0.275542629366\n",
      "Gradient projection reached the stopping criterion\n"
     ]
    }
   ],
   "source": [
    "x, stat = optimizer.minimize(f, x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024365901947021484"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.27554262994756867"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat['fun']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 :\n",
      "\tGradient projection norm 253.722403941\n",
      "\tFunction value 71.8867684491\n",
      "Gradient projection reached the stopping criterion\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-169dbd5438c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "x, stat = optimizer.maximize(f2, x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat['fun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat['time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = np.random.rand(10, 1)\n",
    "X = np.random.rand(500, 10)\n",
    "y = X.dot(w) + np.random.normal(scale=0.1, size=(500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_0 = np.random.rand(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(point, indices=None):\n",
    "    point = point.reshape(point.size, 1)\n",
    "    if indices is None:\n",
    "        indices = np.arange(y.size).tolist()\n",
    "    fun = np.linalg.norm(y[indices] - X[indices].dot(point))**2\n",
    "    grad = -2 * (y[indices] - X[indices].dot(point)).T.dot(X[indices])\n",
    "    return fun, grad.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_gradient(f, w_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### climin AdaDelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gplib.optim.methods import AdaDelta\n",
    "from climin.util import iter_minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "batches = (i for i in iter_minibatches([X, y], batch_size, [0, 0]))\n",
    "def climin_fun(point):\n",
    "    X_batch, y_batch = next(batches)\n",
    "    point = point.reshape(point.size, 1)\n",
    "    fun = np.linalg.norm(y_batch - X_batch.dot(point))**2\n",
    "    grad = -2 * (y_batch - X_batch.dot(point)).T.dot(X_batch)\n",
    "    return grad.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = AdaDelta(iter_per_epoch=y.size/batch_size, n_epoch=20, disp=5, step_rate=1.)\n",
    "x, stat = optimizer.minimize(climin_fun, w_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f(x)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
