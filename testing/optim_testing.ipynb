{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "% load_ext autoreload\n",
    "% autoreload 2\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/Users/IzmailovPavel/Documents/Education/GPproject/gplib/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "Testing gplib.optim \n",
    "## Deterministic methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.random.rand(12, 12)\n",
    "A = A.T.dot(A) + np.eye(12)*0.5\n",
    "b = np.random.rand(12).reshape((12, 1))\n",
    "def f(x):\n",
    "    x = x.reshape((x.size, 1))\n",
    "    fun = x.T.dot(A.dot(x)) / 2 + b.T.dot(x)\n",
    "    grad = A.dot(x) + b\n",
    "    return fun[0, 0], grad.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_0 = np.random.rand(12).reshape(12,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gplib.optim.utility import check_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Difference between calculated and approximated gradients\n",
      "6.70489681598e-06\n"
     ]
    }
   ],
   "source": [
    "check_gradient(f, x_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FGD with armiho step-size rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 :\n",
      "\tGradient norm 70.6821328749\n",
      "\tFunction value [[ 80.03178287]]\n",
      "Iteration  5 :\n",
      "\tGradient norm 61.8215030101\n",
      "\tFunction value [[ 60.4918323]]\n",
      "Iteration  10 :\n",
      "\tGradient norm 54.0880000021\n",
      "\tFunction value [[ 46.044931]]\n",
      "Iteration  15 :\n",
      "\tGradient norm 47.3252453752\n",
      "\tFunction value [[ 35.09207791]]\n",
      "Iteration  20 :\n",
      "\tGradient norm 41.4088444098\n",
      "\tFunction value [[ 26.73609989]]\n",
      "Iteration  25 :\n",
      "\tGradient norm 36.2323250992\n",
      "\tFunction value [[ 20.34954711]]\n",
      "Iteration  30 :\n",
      "\tGradient norm 31.7030170031\n",
      "\tFunction value [[ 15.46481682]]\n",
      "Iteration  35 :\n",
      "\tGradient norm 27.7399520749\n",
      "\tFunction value [[ 11.72745281]]\n",
      "Iteration  40 :\n",
      "\tGradient norm 24.2723191435\n",
      "\tFunction value [[ 8.86736784]]\n",
      "Iteration  45 :\n",
      "\tGradient norm 21.238172501\n",
      "\tFunction value [[ 6.67834782]]\n",
      "Iteration  50 :\n",
      "\tGradient norm 18.583316432\n",
      "\tFunction value [[ 5.00279078]]\n",
      "Iteration  55 :\n",
      "\tGradient norm 16.260333386\n",
      "\tFunction value [[ 3.72017818]]\n",
      "Iteration  60 :\n",
      "\tGradient norm 14.2277351689\n",
      "\tFunction value [[ 2.7383157]]\n",
      "Iteration  65 :\n",
      "\tGradient norm 12.4492209278\n",
      "\tFunction value [[ 1.98665939]]\n",
      "Iteration  70 :\n",
      "\tGradient norm 10.8930282426\n",
      "\tFunction value [[ 1.41122252]]\n",
      "Iteration  75 :\n",
      "\tGradient norm 9.53136552809\n",
      "\tFunction value [[ 0.9706847]]\n",
      "Iteration  80 :\n",
      "\tGradient norm 8.33991549948\n",
      "\tFunction value [[ 0.63341759]]\n",
      "Iteration  85 :\n",
      "\tGradient norm 7.29740077263\n",
      "\tFunction value [[ 0.37521013]]\n",
      "Iteration  90 :\n",
      "\tGradient norm 6.3852038048\n",
      "\tFunction value [[ 0.17752837]]\n",
      "Iteration  95 :\n",
      "\tGradient norm 5.58703436798\n",
      "\tFunction value [[ 0.02618382]]\n"
     ]
    }
   ],
   "source": [
    "from gplib.optim.methods import fgd\n",
    "options = {'maxiter': 100, 'verbose':True, 'print_freq':5}\n",
    "res = fgd(f, x_0, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projected Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gplib.optim.methods import proj_newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 :\n",
      "\tGradient norm 70.6821328749\n",
      "\tFunction value [[ 80.03178287]]\n",
      "Iteration  5 :\n",
      "\tGradient norm 3.81889616913\n",
      "\tFunction value [[ 1.9063685]]\n",
      "Iteration  10 :\n",
      "\tGradient norm 0.926437709055\n",
      "\tFunction value [[-0.40508092]]\n",
      "Iteration  15 :\n",
      "\tGradient norm 0.0602986867766\n",
      "\tFunction value [[-0.46717017]]\n"
     ]
    }
   ],
   "source": [
    "options = {'maxiter': 20, 'print_freq': 5, 'verbose': True}\n",
    "res = proj_newton(f, x_0.reshape(-1), options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scipy_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gplib.optim.methods import scipy_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? scipy_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82.62071070935562,\n",
       " array([ 16.89237506,  24.64533486,  21.4977129 ,  20.54518979,\n",
       "         16.23272345,  22.58979195,  15.73096607,  21.31331506,\n",
       "         24.15904074,  29.12504941,  19.03565451,  17.53973287]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(x_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyper-parameters at iteration 0 : [ 0.90044245  0.98746299  0.95738708  0.04488147  0.22614007]\n",
      "Hyper-parameters at iteration 5 : [ 0.24481864  0.12418623  0.02725765 -0.44295002 -0.19671216]\n",
      "Hyper-parameters at iteration 10 : [ 0.19356864 -0.04140271 -0.02882162 -0.46015683  0.16953619]\n",
      "Hyper-parameters at iteration 15 : [ 0.1984435  -0.04234539 -0.02627296 -0.45865597  0.16965779]\n",
      "Hyper-parameters at iteration 20 : [ 0.19833996 -0.04245949 -0.02637467 -0.45871676  0.16969607]\n"
     ]
    }
   ],
   "source": [
    "options = {'maxiter':20}\n",
    "res = scipy_wrapper(f, x_0.reshape(-1), mydisp=True, print_freq=5, method='L-BFGS-B', jac=True, args=())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "? np.random.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w = np.random.rand(10, 1)\n",
    "X = np.random.rand(500, 10)\n",
    "y = X.dot(w) + np.random.normal(scale=0.1, size=(500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_0 = np.random.rand(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(point, indices=None):\n",
    "    point = point.reshape(point.size, 1)\n",
    "    if indices is None:\n",
    "        indices = np.arange(y.size).tolist()\n",
    "    fun = np.linalg.norm(y[indices] - X[indices].dot(point))**2\n",
    "    grad = -2 * (y[indices] - X[indices].dot(point)).T.dot(X[indices])\n",
    "    return fun, grad.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Difference between calculated and approximated gradients\n",
      "0.000520222081003\n"
     ]
    }
   ],
   "source": [
    "check_gradient(f, w_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gplib.optim.methods import sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_fun(point, indices=None):\n",
    "    fun, grad = f(point, indices)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 :\n",
      "\tStep: 0.001\n",
      "\tParameters [ 0.60204717  0.39577703]\n",
      "Epoch  10 :\n",
      "\tStep: 0.000281838293126\n",
      "\tParameters [ 0.57178817  0.27053413]\n",
      "Epoch  20 :\n",
      "\tStep: 0.000192501227153\n",
      "\tParameters [ 0.56202173  0.22510289]\n",
      "Epoch  30 :\n",
      "\tStep: 0.000154022195564\n",
      "\tParameters [ 0.55647978  0.19802438]\n",
      "Epoch  40 :\n",
      "\tStep: 0.000131482212883\n",
      "\tParameters [ 0.55260143  0.17879205]\n",
      "Epoch  50 :\n",
      "\tStep: 0.000116296460635\n",
      "\tParameters [ 0.54891719  0.16268472]\n",
      "Epoch  60 :\n",
      "\tStep: 0.000105200259787\n",
      "\tParameters [ 0.54756672  0.14979034]\n",
      "Epoch  70 :\n",
      "\tStep: 9.66487136165e-05\n",
      "\tParameters [ 0.54538385  0.13951497]\n",
      "Epoch  80 :\n",
      "\tStep: 8.98049979225e-05\n",
      "\tParameters [ 0.54359413  0.13094623]\n",
      "Epoch  90 :\n",
      "\tStep: 8.41718010112e-05\n",
      "\tParameters [ 0.54295016  0.12270834]\n"
     ]
    }
   ],
   "source": [
    "options = {'maxiter': 100, 'batch_size':20, 'step0': 1e-3, 'verbose': True}\n",
    "res = sgd(sgd_fun, np.copy(w_0).reshape(-1), y.size, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9579283827\n",
      "161.69038231\n",
      "5.9864321102\n"
     ]
    }
   ],
   "source": [
    "print(f(w)[0])\n",
    "print(f(w_0)[0])\n",
    "print(f(res[0])[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gplib.optim.methods import sag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sag_fun(point, indices=None):\n",
    "    fun, grad = f(point, indices)\n",
    "    return fun / len(indices), grad/len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [ 0.57756457  0.31940056]\n",
      "Epoch  10 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [ 109.44476933  140.35383993]\n",
      "Epoch  20 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [  992269.2327949  1099695.0089746]\n",
      "Epoch  30 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [  5.57554416e+09   5.89101376e+09]\n",
      "Epoch  40 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [  2.99981776e+13   3.03569497e+13]\n",
      "Epoch  50 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [  1.14358998e+17   1.13554805e+17]\n",
      "Epoch  60 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [  3.87135412e+20   3.74588739e+20]\n",
      "Epoch  70 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [  1.12022132e+24   1.04130848e+24]\n",
      "Epoch  80 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [  2.41601599e+27   2.02963741e+27]\n",
      "Epoch  90 :\n",
      "\tLipschitz constant estimate: 131.598569812\n",
      "\t [  1.02235539e+30  -6.12806931e+29]\n"
     ]
    }
   ],
   "source": [
    "options = {'maxiter': 100, 'batch_size':20, 'verbose': True}\n",
    "res = sag(f, np.copy(w_0).reshape(-1), y.size, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.794387989324859e+73,\n",
       " array([ -9.26626863e+37,  -9.42963431e+37,  -9.60140599e+37,\n",
       "         -9.49286996e+37,  -9.78953719e+37,  -9.58515245e+37,\n",
       "         -9.50518778e+37,  -9.35724414e+37,  -9.67360106e+37,\n",
       "         -9.47486739e+37]))"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(res[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### climin_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gplib.optim.methods import climin_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?climin_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def climin_fun(point, X_tr, y_tr):\n",
    "    point = point.reshape(point.size, 1)\n",
    "    fun = np.linalg.norm(y_tr - X_tr.dot(point))**2\n",
    "    grad = -2 * (y_tr - X_tr.dot(point)).T.dot(X_tr)\n",
    "    return grad.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using AdaDelta optimizer\n",
      "Iteration  1 :\n",
      "\tGradient norm 4.38364241269\n",
      "Iteration  2 :\n",
      "\tGradient norm 1.60535813026\n",
      "Iteration  3 :\n",
      "\tGradient norm 2.27703856655\n",
      "Iteration  4 :\n",
      "\tGradient norm 2.32651802528\n",
      "Iteration  5 :\n",
      "\tGradient norm 3.63840664374\n",
      "Iteration  6 :\n",
      "\tGradient norm 2.8537127168\n",
      "Iteration  7 :\n",
      "\tGradient norm 2.819877695\n",
      "Iteration  8 :\n",
      "\tGradient norm 1.03807310698\n",
      "Iteration  9 :\n",
      "\tGradient norm 0.845821422092\n",
      "Iteration  10 :\n",
      "\tGradient norm 3.36690520721\n",
      "Iteration  11 :\n",
      "\tGradient norm 1.96386946527\n",
      "Iteration  12 :\n",
      "\tGradient norm 0.6301753459\n",
      "Iteration  13 :\n",
      "\tGradient norm 3.10276953906\n",
      "Iteration  14 :\n",
      "\tGradient norm 1.91970907458\n",
      "Iteration  15 :\n",
      "\tGradient norm 1.84439445425\n",
      "Iteration  16 :\n",
      "\tGradient norm 1.60444434426\n",
      "Iteration  17 :\n",
      "\tGradient norm 1.137982391\n",
      "Iteration  18 :\n",
      "\tGradient norm 1.61941492409\n",
      "Iteration  19 :\n",
      "\tGradient norm 2.32449658193\n",
      "Iteration  20 :\n",
      "\tGradient norm 1.83719393935\n",
      "Iteration  21 :\n",
      "\tGradient norm 3.19372231357\n",
      "Iteration  22 :\n",
      "\tGradient norm 2.40740248513\n",
      "Iteration  23 :\n",
      "\tGradient norm 3.97269281416\n",
      "Iteration  24 :\n",
      "\tGradient norm 2.05851969243\n",
      "Iteration  25 :\n",
      "\tGradient norm 2.3989815528\n",
      "Iteration  26 :\n",
      "\tGradient norm 0.914442892186\n",
      "Iteration  27 :\n",
      "\tGradient norm 2.90835433443\n",
      "Iteration  28 :\n",
      "\tGradient norm 2.31460153824\n",
      "Iteration  29 :\n",
      "\tGradient norm 1.92237479452\n",
      "Iteration  30 :\n",
      "\tGradient norm 1.12871879854\n",
      "Iteration  31 :\n",
      "\tGradient norm 1.31544151798\n",
      "Iteration  32 :\n",
      "\tGradient norm 3.05472392144\n",
      "Iteration  33 :\n",
      "\tGradient norm 1.72209441508\n",
      "Iteration  34 :\n",
      "\tGradient norm 2.48546059468\n",
      "Iteration  35 :\n",
      "\tGradient norm 1.24290134286\n",
      "Iteration  36 :\n",
      "\tGradient norm 3.10209215223\n",
      "Iteration  37 :\n",
      "\tGradient norm 6.12200288289\n",
      "Iteration  38 :\n",
      "\tGradient norm 1.8423836151\n",
      "Iteration  39 :\n",
      "\tGradient norm 1.10228398709\n",
      "Iteration  40 :\n",
      "\tGradient norm 3.18759158025\n",
      "Iteration  41 :\n",
      "\tGradient norm 0.701405903087\n",
      "Iteration  42 :\n",
      "\tGradient norm 0.651963279053\n",
      "Iteration  43 :\n",
      "\tGradient norm 1.54861524459\n",
      "Iteration  44 :\n",
      "\tGradient norm 1.1702358812\n",
      "Iteration  45 :\n",
      "\tGradient norm 2.20686650689\n",
      "Iteration  46 :\n",
      "\tGradient norm 1.80010053537\n",
      "Iteration  47 :\n",
      "\tGradient norm 2.31747210969\n",
      "Iteration  48 :\n",
      "\tGradient norm 0.713184569416\n",
      "Iteration  49 :\n",
      "\tGradient norm 2.9827450481\n",
      "Iteration  50 :\n",
      "\tGradient norm 1.7401675388\n",
      "Iteration  51 :\n",
      "\tGradient norm 3.78810556497\n",
      "Iteration  52 :\n",
      "\tGradient norm 3.36640735693\n",
      "Iteration  53 :\n",
      "\tGradient norm 1.16266105248\n",
      "Iteration  54 :\n",
      "\tGradient norm 0.978414410675\n",
      "Iteration  55 :\n",
      "\tGradient norm 2.46670690084\n",
      "Iteration  56 :\n",
      "\tGradient norm 1.38225327798\n",
      "Iteration  57 :\n",
      "\tGradient norm 3.3015046263\n",
      "Iteration  58 :\n",
      "\tGradient norm 2.07607971558\n",
      "Iteration  59 :\n",
      "\tGradient norm 2.85319983806\n",
      "Iteration  60 :\n",
      "\tGradient norm 0.935240041395\n",
      "Iteration  61 :\n",
      "\tGradient norm 1.85164095194\n",
      "Iteration  62 :\n",
      "\tGradient norm 2.44609077999\n",
      "Iteration  63 :\n",
      "\tGradient norm 3.50211481425\n",
      "Iteration  64 :\n",
      "\tGradient norm 1.49358743828\n",
      "Iteration  65 :\n",
      "\tGradient norm 3.99025394486\n",
      "Iteration  66 :\n",
      "\tGradient norm 3.84613897228\n",
      "Iteration  67 :\n",
      "\tGradient norm 1.37042115538\n",
      "Iteration  68 :\n",
      "\tGradient norm 0.724189668032\n",
      "Iteration  69 :\n",
      "\tGradient norm 3.41537912689\n",
      "Iteration  70 :\n",
      "\tGradient norm 1.37025445631\n",
      "Iteration  71 :\n",
      "\tGradient norm 3.30417499578\n",
      "Iteration  72 :\n",
      "\tGradient norm 1.83571944366\n",
      "Iteration  73 :\n",
      "\tGradient norm 0.615105405981\n",
      "Iteration  74 :\n",
      "\tGradient norm 3.58924337893\n",
      "Iteration  75 :\n",
      "\tGradient norm 2.52090104077\n",
      "Iteration  76 :\n",
      "\tGradient norm 1.81601741331\n",
      "Iteration  77 :\n",
      "\tGradient norm 3.05536883443\n",
      "Iteration  78 :\n",
      "\tGradient norm 3.33130398775\n",
      "Iteration  79 :\n",
      "\tGradient norm 1.08866774648\n",
      "Iteration  80 :\n",
      "\tGradient norm 3.6120959696\n",
      "Iteration  81 :\n",
      "\tGradient norm 1.59628902933\n",
      "Iteration  82 :\n",
      "\tGradient norm 3.06820793563\n",
      "Iteration  83 :\n",
      "\tGradient norm 2.68520175185\n",
      "Iteration  84 :\n",
      "\tGradient norm 0.695275111857\n",
      "Iteration  85 :\n",
      "\tGradient norm 1.12311595367\n",
      "Iteration  86 :\n",
      "\tGradient norm 1.54860011193\n",
      "Iteration  87 :\n",
      "\tGradient norm 0.582573770433\n",
      "Iteration  88 :\n",
      "\tGradient norm 3.56359885575\n",
      "Iteration  89 :\n",
      "\tGradient norm 2.38459851032\n",
      "Iteration  90 :\n",
      "\tGradient norm 2.43347052572\n",
      "Iteration  91 :\n",
      "\tGradient norm 0.814954576512\n",
      "Iteration  92 :\n",
      "\tGradient norm 2.15172207352\n",
      "Iteration  93 :\n",
      "\tGradient norm 0.876742330881\n",
      "Iteration  94 :\n",
      "\tGradient norm 1.61800993818\n",
      "Iteration  95 :\n",
      "\tGradient norm 2.58279364555\n",
      "Iteration  96 :\n",
      "\tGradient norm 3.80298114149\n",
      "Iteration  97 :\n",
      "\tGradient norm 0.889866820094\n",
      "Iteration  98 :\n",
      "\tGradient norm 1.68616565303\n",
      "Iteration  99 :\n",
      "\tGradient norm 1.02453906494\n",
      "Iteration  100 :\n",
      "\tGradient norm 2.66914400176\n"
     ]
    }
   ],
   "source": [
    "opts = {'maxiter': 100, 'verbose': True, 'batch_size':20, 'step_rate': 0.7, 'decay': 0.8}\n",
    "res = climin_wrapper(climin_fun, w_0.reshape(-1), X, y, opts, method='AdaDelta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.034111864854423"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(res[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color:#FF0000\";>Problems</b>:\n",
    "<ul>\n",
    "    <li> Docstrings for some methods lack or are outdated\n",
    "    <li> Different methods have differerent names for parameters (especially related to printing progress)\n",
    "    <li> Bad output format\n",
    "    <li> Different methods have different requirements for input parameters shape (initial point and gradient)\n",
    "    <li> SGD method changes the given initial point instead of copying it\n",
    "    <li> SAG seems to not work\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
